{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56451948-8c62-4b87-a76f-1af938b117cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ NOTEBOOK 5: DISPUTE RESOLUTION PREDICTION SYSTEM\n",
      "======================================================================\n",
      "\n",
      "‚úÖ All libraries imported successfully!\n",
      "\n",
      "üì¶ This notebook will:\n",
      "   1. Load your trained model\n",
      "   2. Create prediction functions\n",
      "   3. Test with sample complaints\n",
      "   4. Generate prediction reports\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# CELL 1: Import All Required Libraries\n",
    "# ==================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ NOTEBOOK 5: DISPUTE RESOLUTION PREDICTION SYSTEM\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")\n",
    "print(\"\\nüì¶ This notebook will:\")\n",
    "print(\"   1. Load your trained model\")\n",
    "print(\"   2. Create prediction functions\")\n",
    "print(\"   3. Test with sample complaints\")\n",
    "print(\"   4. Generate prediction reports\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c5061a-db9f-4869-b25d-528172a50e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ LOADING SAVED MODEL COMPONENTS\n",
      "======================================================================\n",
      "\n",
      "üîÑ Loading components...\n",
      "\n",
      "1Ô∏è‚É£ Loading trained model...\n",
      "   ‚úÖ Model loaded: LinearSVC\n",
      "\n",
      "2Ô∏è‚É£ Loading TF-IDF vectorizer...\n",
      "   ‚úÖ Vectorizer loaded: 3000 features\n",
      "\n",
      "3Ô∏è‚É£ Loading target encoder...\n",
      "   ‚úÖ Target encoder loaded: 3 classes\n",
      "   Classes: ['favor_seller', 'favour_customer', 'split_payment']\n",
      "\n",
      "4Ô∏è‚É£ Loading feature info...\n",
      "   ‚úÖ Feature info loaded\n",
      "   Numerical features: ['processed_word_count', 'negative_word_count', 'positive_word_count', 'urgency_indicator', 'financial_terms_count', 'question_count', 'exclamation_count']\n",
      "\n",
      "5Ô∏è‚É£ Loading model metadata...\n",
      "   ‚úÖ Metadata loaded\n",
      "   Model: Linear SVC\n",
      "   Accuracy: 0.8192 (81.92%)\n",
      "   F1-Score: 0.7663\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ALL COMPONENTS LOADED SUCCESSFULLY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# CELL 2: Load Saved Model and Components\n",
    "# ==================================================\n",
    "\n",
    "print(\"üìÇ LOADING SAVED MODEL COMPONENTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "models_dir = '../models/'\n",
    "\n",
    "# Load all components\n",
    "print(\"\\nüîÑ Loading components...\")\n",
    "\n",
    "try:\n",
    "    # 1. Load model\n",
    "    print(\"\\n1Ô∏è‚É£ Loading trained model...\")\n",
    "    with open(f'{models_dir}dispute_resolution_model_latest.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    print(f\"   ‚úÖ Model loaded: {type(model).__name__}\")\n",
    "    \n",
    "    # 2. Load TF-IDF vectorizer\n",
    "    print(\"\\n2Ô∏è‚É£ Loading TF-IDF vectorizer...\")\n",
    "    with open(f'{models_dir}tfidf_vectorizer_latest.pkl', 'rb') as f:\n",
    "        tfidf_vectorizer = pickle.load(f)\n",
    "    print(f\"   ‚úÖ Vectorizer loaded: {tfidf_vectorizer.max_features} features\")\n",
    "    \n",
    "    # 3. Load target encoder\n",
    "    print(\"\\n3Ô∏è‚É£ Loading target encoder...\")\n",
    "    with open(f'{models_dir}target_encoder_latest.pkl', 'rb') as f:\n",
    "        target_encoder = pickle.load(f)\n",
    "    print(f\"   ‚úÖ Target encoder loaded: {len(target_encoder.classes_)} classes\")\n",
    "    print(f\"   Classes: {list(target_encoder.classes_)}\")\n",
    "    \n",
    "    # 4. Load feature info\n",
    "    print(\"\\n4Ô∏è‚É£ Loading feature info...\")\n",
    "    with open(f'{models_dir}feature_info_latest.pkl', 'rb') as f:\n",
    "        feature_info = pickle.load(f)\n",
    "    print(f\"   ‚úÖ Feature info loaded\")\n",
    "    print(f\"   Numerical features: {feature_info['numerical_features']}\")\n",
    "    \n",
    "    # 5. Load metadata\n",
    "    print(\"\\n5Ô∏è‚É£ Loading model metadata...\")\n",
    "    with open(f'{models_dir}model_metadata_latest.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    print(f\"   ‚úÖ Metadata loaded\")\n",
    "    print(f\"   Model: {metadata['model_name']}\")\n",
    "    print(f\"   Accuracy: {metadata['accuracy']:.4f} ({metadata['accuracy']*100:.2f}%)\")\n",
    "    print(f\"   F1-Score: {metadata['f1_score']:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ ALL COMPONENTS LOADED SUCCESSFULLY!\")\n",
    "    print(\"=\"*70)\n",
    "    h\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n‚ùå ERROR: Could not find model files!\")\n",
    "    print(f\"   {e}\")\n",
    "    print(\"\\n   Make sure you completed Notebook 4 and saved the model.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERROR loading components: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561f104c-340e-4bfd-b025-ed90ecedb927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ DEFINING TEXT PREPROCESSING FUNCTIONS\n",
      "======================================================================\n",
      "‚úÖ Text preprocessing functions defined:\n",
      "   ‚Ä¢ clean_text() - Removes noise and special characters\n",
      "   ‚Ä¢ remove_stopwords() - Removes common words\n",
      "   ‚Ä¢ extract_text_features() - Extracts numerical features\n",
      "\n",
      "‚ö° These are the SAME functions used during training\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# CELL 3: Define Text Preprocessing Functions\n",
    "# ==================================================\n",
    "\n",
    "print(\"üßπ DEFINING TEXT PREPROCESSING FUNCTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and preprocess complaint text\n",
    "    SAME function used in training (Notebook 3)\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "    \n",
    "    # Convert to string\n",
    "    text = str(text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove XXXX patterns (redaction)\n",
    "    text = re.sub(r'x{2,}', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove phone numbers\n",
    "    text = re.sub(r'\\d{3}[-.\\s]?\\d{3}[-.\\s]?\\d{4}', '', text)\n",
    "    text = re.sub(r'\\(\\d{3}\\)\\s*\\d{3}[-.\\s]?\\d{4}', '', text)\n",
    "    \n",
    "    # Remove account numbers\n",
    "    text = re.sub(r'(account|acct|acc)[\\s#]*\\d+', '', text)\n",
    "    \n",
    "    # Remove dates\n",
    "    text = re.sub(r'\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}', '', text)\n",
    "    \n",
    "    # Replace currency amounts with placeholder\n",
    "    text = re.sub(r'\\$\\s?\\d+[\\d,]*\\.?\\d*', 'AMOUNT', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove special characters but keep basic punctuation\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', text)\n",
    "    \n",
    "    # Trim\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Remove common English stopwords\n",
    "    SAME function used in training (Notebook 3)\n",
    "    \"\"\"\n",
    "    stopwords = {\n",
    "        'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \n",
    "        'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself',\n",
    "        'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them',\n",
    "        'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this',\n",
    "        'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been',\n",
    "        'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing',\n",
    "        'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "        'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between',\n",
    "        'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to',\n",
    "        'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n",
    "        'further', 'then', 'once'\n",
    "    }\n",
    "    \n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def extract_text_features(text):\n",
    "    \"\"\"\n",
    "    Extract numerical features from text\n",
    "    SAME features used in training (Notebook 3)\n",
    "    \"\"\"\n",
    "    # Negative words\n",
    "    negative_words = ['terrible', 'horrible', 'worst', 'awful', 'bad', 'poor', \n",
    "                     'unacceptable', 'frustrated', 'angry', 'disappointed', 'never']\n",
    "    negative_count = sum(1 for word in text.split() if word in negative_words)\n",
    "    \n",
    "    # Positive words\n",
    "    positive_words = ['good', 'great', 'excellent', 'satisfied', 'happy', \n",
    "                     'resolved', 'helpful', 'thank']\n",
    "    positive_count = sum(1 for word in text.split() if word in positive_words)\n",
    "    \n",
    "    # Urgency words\n",
    "    urgency_words = ['urgent', 'immediately', 'asap', 'emergency', 'critical', \n",
    "                    'important', 'serious', 'severe']\n",
    "    urgency_indicator = 1 if any(word in text.split() for word in urgency_words) else 0\n",
    "    \n",
    "    # Financial terms\n",
    "    financial_terms = ['payment', 'amount', 'fee', 'charge', 'refund', 'money', \n",
    "                      'balance', 'account', 'credit', 'debit', 'transaction']\n",
    "    financial_count = sum(1 for word in text.split() if word in financial_terms)\n",
    "    \n",
    "    # Question marks\n",
    "    question_count = text.count('?')\n",
    "    \n",
    "    # Exclamation marks\n",
    "    exclamation_count = text.count('!')\n",
    "    \n",
    "    # Word count\n",
    "    word_count = len(text.split())\n",
    "    \n",
    "    return {\n",
    "        'processed_word_count': word_count,\n",
    "        'negative_word_count': negative_count,\n",
    "        'positive_word_count': positive_count,\n",
    "        'urgency_indicator': urgency_indicator,\n",
    "        'financial_terms_count': financial_count,\n",
    "        'question_count': question_count,\n",
    "        'exclamation_count': exclamation_count\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Text preprocessing functions defined:\")\n",
    "print(\"   ‚Ä¢ clean_text() - Removes noise and special characters\")\n",
    "print(\"   ‚Ä¢ remove_stopwords() - Removes common words\")\n",
    "print(\"   ‚Ä¢ extract_text_features() - Extracts numerical features\")\n",
    "print(\"\\n‚ö° These are the SAME functions used during training\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8bc6849-b969-4c31-96a8-6f2f9e7e4ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ CREATING MAIN PREDICTION FUNCTION\n",
      "======================================================================\n",
      "‚úÖ Main prediction function created: predict_dispute_resolution()\n",
      "\n",
      "üìù Usage:\n",
      "   result = predict_dispute_resolution('Your complaint text here')\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# CELL 4: Create Main Prediction Function\n",
    "# ==================================================\n",
    "\n",
    "print(\"üéØ CREATING MAIN PREDICTION FUNCTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def predict_dispute_resolution(complaint_text):\n",
    "    \"\"\"\n",
    "    Main function to predict dispute resolution outcome\n",
    "    \n",
    "    Args:\n",
    "        complaint_text (str): Raw complaint text from customer\n",
    "        \n",
    "    Returns:\n",
    "        dict: Prediction results with confidence scores\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Clean the text\n",
    "    cleaned_text = clean_text(complaint_text)\n",
    "    \n",
    "    # Step 2: Remove stopwords\n",
    "    processed_text = remove_stopwords(cleaned_text)\n",
    "    \n",
    "    # Check if text is empty after processing\n",
    "    if not processed_text or len(processed_text) < 5:\n",
    "        return {\n",
    "            'error': 'Text too short or empty after preprocessing',\n",
    "            'original_text': complaint_text[:100]\n",
    "        }\n",
    "    \n",
    "    # Step 3: Extract text features\n",
    "    text_features = extract_text_features(processed_text)\n",
    "    \n",
    "    # Step 4: Convert text to TF-IDF features\n",
    "    text_tfidf = tfidf_vectorizer.transform([processed_text])\n",
    "    \n",
    "    # Step 5: Create numerical features array\n",
    "    numerical_features_values = np.array([[\n",
    "        text_features['processed_word_count'],\n",
    "        text_features['negative_word_count'],\n",
    "        text_features['positive_word_count'],\n",
    "        text_features['urgency_indicator'],\n",
    "        text_features['financial_terms_count'],\n",
    "        text_features['question_count'],\n",
    "        text_features['exclamation_count']\n",
    "    ]])\n",
    "    \n",
    "    # Step 6: Combine features (keep sparse)\n",
    "    from scipy.sparse import csr_matrix, hstack as sparse_hstack\n",
    "    numerical_sparse = csr_matrix(numerical_features_values)\n",
    "    X_combined = sparse_hstack([text_tfidf, numerical_sparse])\n",
    "    \n",
    "    # Step 7: Make prediction\n",
    "    prediction_encoded = model.predict(X_combined)[0]\n",
    "    prediction_label = target_encoder.inverse_transform([prediction_encoded])[0]\n",
    "    \n",
    "    # Step 8: Get confidence scores (if model supports decision_function)\n",
    "    try:\n",
    "        decision_scores = model.decision_function(X_combined)[0]\n",
    "        \n",
    "        # Convert to confidence percentages\n",
    "        # For multiclass SVC, decision_function returns scores for each class\n",
    "        if len(decision_scores) == len(target_encoder.classes_):\n",
    "            # Softmax-like transformation\n",
    "            exp_scores = np.exp(decision_scores - np.max(decision_scores))\n",
    "            confidence_scores = exp_scores / exp_scores.sum()\n",
    "            \n",
    "            confidence_dict = {}\n",
    "            for label, score in zip(target_encoder.classes_, confidence_scores):\n",
    "                confidence_dict[label] = float(score)\n",
    "        else:\n",
    "            confidence_dict = {prediction_label: 1.0}\n",
    "    except:\n",
    "        # If decision_function not available, just show predicted class\n",
    "        confidence_dict = {prediction_label: 1.0}\n",
    "    \n",
    "    # Step 9: Return results\n",
    "    return {\n",
    "        'prediction': prediction_label,\n",
    "        'confidence_scores': confidence_dict,\n",
    "        'text_features': text_features,\n",
    "        'cleaned_text': cleaned_text[:200],\n",
    "        'processed_text': processed_text[:200]\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Main prediction function created: predict_dispute_resolution()\")\n",
    "print(\"\\nüìù Usage:\")\n",
    "print(\"   result = predict_dispute_resolution('Your complaint text here')\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c6f6bc7-4320-46f0-ad33-31dd034f738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pretty print function created: print_prediction_result()\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# CELL 5: Create Pretty Print Function for Results\n",
    "# ==================================================\n",
    "\n",
    "def print_prediction_result(result):\n",
    "    \"\"\"\n",
    "    Pretty print prediction results\n",
    "    \"\"\"\n",
    "    if 'error' in result:\n",
    "        print(\"‚ùå ERROR:\", result['error'])\n",
    "        return\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\" üéØ DISPUTE RESOLUTION PREDICTION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Show prediction\n",
    "    prediction = result['prediction']\n",
    "    print(f\"\\nüèÜ PREDICTED OUTCOME: {prediction.upper()}\")\n",
    "    \n",
    "    # Show confidence scores\n",
    "    print(f\"\\nüìä CONFIDENCE SCORES:\")\n",
    "    for label, score in sorted(result['confidence_scores'].items(), \n",
    "                               key=lambda x: x[1], reverse=True):\n",
    "        bar_length = int(score * 40)\n",
    "        bar = '‚ñà' * bar_length + '‚ñë' * (40 - bar_length)\n",
    "        print(f\"   {label:20s} {bar} {score*100:.2f}%\")\n",
    "    \n",
    "    # Show text features\n",
    "    print(f\"\\nüìà TEXT FEATURES:\")\n",
    "    features = result['text_features']\n",
    "    print(f\"   ‚Ä¢ Word count: {features['processed_word_count']}\")\n",
    "    print(f\"   ‚Ä¢ Negative words: {features['negative_word_count']}\")\n",
    "    print(f\"   ‚Ä¢ Positive words: {features['positive_word_count']}\")\n",
    "    print(f\"   ‚Ä¢ Financial terms: {features['financial_terms_count']}\")\n",
    "    print(f\"   ‚Ä¢ Urgency: {'Yes' if features['urgency_indicator'] else 'No'}\")\n",
    "    print(f\"   ‚Ä¢ Questions: {features['question_count']}\")\n",
    "    print(f\"   ‚Ä¢ Exclamations: {features['exclamation_count']}\")\n",
    "    \n",
    "    # Show interpretation\n",
    "    print(f\"\\nüí° INTERPRETATION:\")\n",
    "    if prediction == 'favour_customer':\n",
    "        print(\"   ‚Üí Customer should WIN this dispute\")\n",
    "        print(\"   ‚Üí Recommendation: Provide refund or relief to customer\")\n",
    "    elif prediction == 'favor_seller':\n",
    "        print(\"   ‚Üí Seller/Company should WIN this dispute\")\n",
    "        print(\"   ‚Üí Recommendation: Uphold company position\")\n",
    "    else:  # split_payment\n",
    "        print(\"   ‚Üí COMPROMISE recommended\")\n",
    "        print(\"   ‚Üí Recommendation: Partial refund or non-monetary relief\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "print(\"‚úÖ Pretty print function created: print_prediction_result()\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28d0ddb4-a131-482d-b089-42c61b1c4a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TEST 1: Customer Should Win\n",
      "======================================================================\n",
      "\n",
      "üìù COMPLAINT TEXT:\n",
      "I opened a credit card account with this company 3 years ago. I always paid \n",
      "my bills on time and never missed a payment. Last month, they charged me a \n",
      "$50 late fee even though I paid 2 days before the due date. I have proof of \n",
      "payment from my bank statement. When I called customer service, they were \n",
      "rude and refused to remove the fee. This is completely unacceptable and unfair. \n",
      "I want my $50 refunded immediately. I have been a loyal customer and this \n",
      "treatment is terrible. I will never use this company again.\n",
      "\n",
      "üîÑ Making prediction...\n",
      "======================================================================\n",
      " üéØ DISPUTE RESOLUTION PREDICTION\n",
      "======================================================================\n",
      "\n",
      "üèÜ PREDICTED OUTCOME: FAVOUR_CUSTOMER\n",
      "\n",
      "üìä CONFIDENCE SCORES:\n",
      "   favour_customer      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 39.58%\n",
      "   favor_seller         ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 39.41%\n",
      "   split_payment        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 21.01%\n",
      "\n",
      "üìà TEXT FEATURES:\n",
      "   ‚Ä¢ Word count: 56\n",
      "   ‚Ä¢ Negative words: 3\n",
      "   ‚Ä¢ Positive words: 0\n",
      "   ‚Ä¢ Financial terms: 4\n",
      "   ‚Ä¢ Urgency: No\n",
      "   ‚Ä¢ Questions: 0\n",
      "   ‚Ä¢ Exclamations: 0\n",
      "\n",
      "üí° INTERPRETATION:\n",
      "   ‚Üí Customer should WIN this dispute\n",
      "   ‚Üí Recommendation: Provide refund or relief to customer\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# CELL 6: Test Prediction - Sample 1\n",
    "# ==================================================\n",
    "\n",
    "print(\"üß™ TEST 1: Customer Should Win\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "sample_complaint_1 = \"\"\"\n",
    "I opened a credit card account with this company 3 years ago. I always paid \n",
    "my bills on time and never missed a payment. Last month, they charged me a \n",
    "$50 late fee even though I paid 2 days before the due date. I have proof of \n",
    "payment from my bank statement. When I called customer service, they were \n",
    "rude and refused to remove the fee. This is completely unacceptable and unfair. \n",
    "I want my $50 refunded immediately. I have been a loyal customer and this \n",
    "treatment is terrible. I will never use this company again.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù COMPLAINT TEXT:\")\n",
    "print(sample_complaint_1.strip())\n",
    "\n",
    "print(\"\\nüîÑ Making prediction...\")\n",
    "result = predict_dispute_resolution(sample_complaint_1)\n",
    "\n",
    "print_prediction_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e747e17-c921-4e8e-b6b6-4a9315b2eeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TEST 2: Seller Should Win\n",
      "======================================================================\n",
      "\n",
      "üìù COMPLAINT TEXT:\n",
      "I applied for a loan and was denied. The company said I don't meet their \n",
      "credit requirements. I think this is wrong but when I look at my credit \n",
      "report, I see that I have several late payments and my credit score is \n",
      "below 600. The company clearly explained their requirements on their \n",
      "website before I applied. I understand they have lending standards.\n",
      "\n",
      "üîÑ Making prediction...\n",
      "======================================================================\n",
      " üéØ DISPUTE RESOLUTION PREDICTION\n",
      "======================================================================\n",
      "\n",
      "üèÜ PREDICTED OUTCOME: FAVOR_SELLER\n",
      "\n",
      "üìä CONFIDENCE SCORES:\n",
      "   favor_seller         ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 66.09%\n",
      "   favour_customer      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 19.43%\n",
      "   split_payment        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 14.48%\n",
      "\n",
      "üìà TEXT FEATURES:\n",
      "   ‚Ä¢ Word count: 31\n",
      "   ‚Ä¢ Negative words: 0\n",
      "   ‚Ä¢ Positive words: 0\n",
      "   ‚Ä¢ Financial terms: 3\n",
      "   ‚Ä¢ Urgency: No\n",
      "   ‚Ä¢ Questions: 0\n",
      "   ‚Ä¢ Exclamations: 0\n",
      "\n",
      "üí° INTERPRETATION:\n",
      "   ‚Üí Seller/Company should WIN this dispute\n",
      "   ‚Üí Recommendation: Uphold company position\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# CELL 7: Test Prediction - Sample 2\n",
    "# ==================================================\n",
    "\n",
    "print(\"üß™ TEST 2: Seller Should Win\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "sample_complaint_2 = \"\"\"\n",
    "I applied for a loan and was denied. The company said I don't meet their \n",
    "credit requirements. I think this is wrong but when I look at my credit \n",
    "report, I see that I have several late payments and my credit score is \n",
    "below 600. The company clearly explained their requirements on their \n",
    "website before I applied. I understand they have lending standards.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù COMPLAINT TEXT:\")\n",
    "print(sample_complaint_2.strip())\n",
    "\n",
    "print(\"\\nüîÑ Making prediction...\")\n",
    "result = predict_dispute_resolution(sample_complaint_2)\n",
    "\n",
    "print_prediction_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6561755a-8a18-4c4a-a376-71b2d5cf3c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TEST 3: Compromise/Split Payment\n",
      "======================================================================\n",
      "\n",
      "üìù COMPLAINT TEXT:\n",
      "I purchased a product that arrived damaged. The company offered to replace \n",
      "it but I would have to pay for return shipping which costs $30. I think \n",
      "they should cover the return shipping since the product was damaged when \n",
      "it arrived. However, I understand they have a return policy. Maybe we can \n",
      "split the cost?\n",
      "\n",
      "üîÑ Making prediction...\n",
      "======================================================================\n",
      " üéØ DISPUTE RESOLUTION PREDICTION\n",
      "======================================================================\n",
      "\n",
      "üèÜ PREDICTED OUTCOME: FAVOR_SELLER\n",
      "\n",
      "üìä CONFIDENCE SCORES:\n",
      "   favor_seller         ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 59.71%\n",
      "   favour_customer      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 27.70%\n",
      "   split_payment        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 12.60%\n",
      "\n",
      "üìà TEXT FEATURES:\n",
      "   ‚Ä¢ Word count: 31\n",
      "   ‚Ä¢ Negative words: 0\n",
      "   ‚Ä¢ Positive words: 0\n",
      "   ‚Ä¢ Financial terms: 0\n",
      "   ‚Ä¢ Urgency: No\n",
      "   ‚Ä¢ Questions: 1\n",
      "   ‚Ä¢ Exclamations: 0\n",
      "\n",
      "üí° INTERPRETATION:\n",
      "   ‚Üí Seller/Company should WIN this dispute\n",
      "   ‚Üí Recommendation: Uphold company position\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# CELL 8: Test Prediction - Sample 3\n",
    "# ==================================================\n",
    "\n",
    "print(\"üß™ TEST 3: Compromise/Split Payment\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "sample_complaint_3 = \"\"\"\n",
    "I purchased a product that arrived damaged. The company offered to replace \n",
    "it but I would have to pay for return shipping which costs $30. I think \n",
    "they should cover the return shipping since the product was damaged when \n",
    "it arrived. However, I understand they have a return policy. Maybe we can \n",
    "split the cost?\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù COMPLAINT TEXT:\")\n",
    "print(sample_complaint_3.strip())\n",
    "\n",
    "print(\"\\nüîÑ Making prediction...\")\n",
    "result = predict_dispute_resolution(sample_complaint_3)\n",
    "\n",
    "print_prediction_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93932889-cec7-4afe-86ee-fc5ed9a91967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ CREATING BATCH PREDICTION FUNCTION\n",
      "======================================================================\n",
      "‚úÖ Batch prediction function created: predict_batch_complaints()\n",
      "\n",
      "üìù Usage:\n",
      "   complaints = ['complaint 1', 'complaint 2', 'complaint 3']\n",
      "   results_df = predict_batch_complaints(complaints)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# CELL 9: Create Batch Prediction Function\n",
    "# ==================================================\n",
    "\n",
    "print(\"üì¶ CREATING BATCH PREDICTION FUNCTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def predict_batch_complaints(complaints_list):\n",
    "    \"\"\"\n",
    "    Predict outcomes for multiple complaints at once\n",
    "    \n",
    "    Args:\n",
    "        complaints_list: List of complaint texts or DataFrame with 'complaint_text' column\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to DataFrame if it's a list\n",
    "    if isinstance(complaints_list, list):\n",
    "        df = pd.DataFrame({'complaint_text': complaints_list})\n",
    "    else:\n",
    "        df = complaints_list.copy()\n",
    "    \n",
    "    print(f\"üîÑ Processing {len(df)} complaints...\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        complaint_text = row['complaint_text'] if 'complaint_text' in row else row[0]\n",
    "        \n",
    "        # Make prediction\n",
    "        result = predict_dispute_resolution(complaint_text)\n",
    "        \n",
    "        if 'error' in result:\n",
    "            results.append({\n",
    "                'complaint_id': idx,\n",
    "                'prediction': 'ERROR',\n",
    "                'confidence': 0,\n",
    "                'error': result['error']\n",
    "            })\n",
    "        else:\n",
    "            max_confidence = max(result['confidence_scores'].values())\n",
    "            results.append({\n",
    "                'complaint_id': idx,\n",
    "                'complaint_text': complaint_text[:100] + '...',\n",
    "                'prediction': result['prediction'],\n",
    "                'confidence': max_confidence,\n",
    "                'word_count': result['text_features']['processed_word_count'],\n",
    "                'negative_words': result['text_features']['negative_word_count'],\n",
    "                'positive_words': result['text_features']['positive_word_count']\n",
    "            })\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"   Processed {idx + 1}/{len(df)} complaints...\")\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(f\"\\n‚úÖ Batch prediction complete!\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "print(\"‚úÖ Batch prediction function created: predict_batch_complaints()\")\n",
    "print(\"\\nüìù Usage:\")\n",
    "print(\"   complaints = ['complaint 1', 'complaint 2', 'complaint 3']\")\n",
    "print(\"   results_df = predict_batch_complaints(complaints)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bff45373-8192-4257-85bb-c046900a7060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING BATCH PREDICTION\n",
      "======================================================================\n",
      "\n",
      "üìù Processing 5 sample complaints...\n",
      "\n",
      "üîÑ Processing 5 complaints...\n",
      "\n",
      "‚úÖ Batch prediction complete!\n",
      "\n",
      "üìä BATCH PREDICTION RESULTS:\n",
      "======================================================================\n",
      " complaint_id                                                                          complaint_text   prediction  confidence  word_count  negative_words  positive_words\n",
      "            0      Company charged me fees I did not authorize. This is fraud! I want full refund.... favor_seller    0.508967           9               0               0\n",
      "            1        Applied for credit card but was denied due to low credit score. I understand.... favor_seller    0.662264           9               0               0\n",
      "            2      Product was damaged. Company will replace but I need to pay shipping. Not fair.... favor_seller    0.623196          10               0               0\n",
      "            3 Been waiting 3 months for refund. Called customer service 10 times. Very frustrated!... favor_seller    0.547913          11               0               0\n",
      "            4                        Service was okay but could be better. No major issues though.... favor_seller    0.782446           8               0               0\n",
      "\n",
      "üìà SUMMARY STATISTICS:\n",
      "----------------------------------------------------------------------\n",
      "prediction\n",
      "favor_seller    5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average confidence: 62.50%\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# CELL 10: Test Batch Prediction\n",
    "# ==================================================\n",
    "\n",
    "print(\"üß™ TESTING BATCH PREDICTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create sample batch of complaints\n",
    "test_complaints = [\n",
    "    \"Company charged me fees I did not authorize. This is fraud! I want full refund.\",\n",
    "    \"Applied for credit card but was denied due to low credit score. I understand.\",\n",
    "    \"Product was damaged. Company will replace but I need to pay shipping. Not fair.\",\n",
    "    \"Been waiting 3 months for refund. Called customer service 10 times. Very frustrated!\",\n",
    "    \"Service was okay but could be better. No major issues though.\"\n",
    "]\n",
    "\n",
    "print(f\"\\nüìù Processing {len(test_complaints)} sample complaints...\\n\")\n",
    "\n",
    "# Run batch prediction\n",
    "results_df = predict_batch_complaints(test_complaints)\n",
    "\n",
    "print(\"\\nüìä BATCH PREDICTION RESULTS:\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nüìà SUMMARY STATISTICS:\")\n",
    "print(\"-\"*70)\n",
    "print(results_df['prediction'].value_counts())\n",
    "\n",
    "print(f\"\\nAverage confidence: {results_df['confidence'].mean():.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8323ff1-6f7c-4122-ae62-28272c6d8ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ CREATING PREDICTION EXPORT FUNCTION\n",
      "======================================================================\n",
      "‚úÖ Export function created: save_predictions()\n",
      "\n",
      "üìù Usage:\n",
      "   save_predictions(results_df)\n",
      "   save_predictions(results_df, 'my_predictions.csv')\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# CELL 11: Create Function to Save Predictions\n",
    "# ==================================================\n",
    "\n",
    "print(\"üíæ CREATING PREDICTION EXPORT FUNCTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def save_predictions(results_df, filename=None):\n",
    "    \"\"\"\n",
    "    Save prediction results to CSV file\n",
    "    \"\"\"\n",
    "    \n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f'predictions_{timestamp}.csv'\n",
    "    \n",
    "    output_path = f'../data/processed/{filename}'\n",
    "    \n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Predictions saved to: {output_path}\")\n",
    "    print(f\"   ‚Ä¢ Records: {len(results_df)}\")\n",
    "    print(f\"   ‚Ä¢ File size: {pd.read_csv(output_path).memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "print(\"‚úÖ Export function created: save_predictions()\")\n",
    "print(\"\\nüìù Usage:\")\n",
    "print(\"   save_predictions(results_df)\")\n",
    "print(\"   save_predictions(results_df, 'my_predictions.csv')\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a3a56e5-2b05-4c1f-9e9b-a12c6b90fd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ INTERACTIVE PREDICTION INTERFACE\n",
      "======================================================================\n",
      "‚úÖ Interactive interface created: interactive_predict()\n",
      "\n",
      "üìù To use the interactive predictor, run:\n",
      "   interactive_predict()\n",
      "\n",
      "‚ö†Ô∏è Note: This works in Jupyter notebooks with input support\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# CELL 12: Interactive Prediction Interface\n",
    "# ==================================================\n",
    "\n",
    "print(\"üéÆ INTERACTIVE PREDICTION INTERFACE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def interactive_predict():\n",
    "    \"\"\"\n",
    "    Interactive function to get predictions for custom complaints\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" üéØ ESCROW DISPUTE RESOLUTION PREDICTOR\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nEnter a complaint text to get a prediction.\")\n",
    "    print(\"Type 'quit' to exit.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        print(\"-\"*70)\n",
    "        complaint = input(\"Enter complaint text: \")\n",
    "        \n",
    "        if complaint.lower() == 'quit':\n",
    "            print(\"\\nüëã Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if len(complaint) < 10:\n",
    "            print(\"‚ö†Ô∏è Complaint too short! Please enter at least 10 characters.\\n\")\n",
    "            continue\n",
    "        \n",
    "        print(\"\\nüîÑ Processing...\")\n",
    "        result = predict_dispute_resolution(complaint)\n",
    "        print_prediction_result(result)\n",
    "        \n",
    "        print(\"\\n\")\n",
    "\n",
    "print(\"‚úÖ Interactive interface created: interactive_predict()\")\n",
    "print(\"\\nüìù To use the interactive predictor, run:\")\n",
    "print(\"   interactive_predict()\")\n",
    "print(\"\\n‚ö†Ô∏è Note: This works in Jupyter notebooks with input support\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cb83244-3200-488b-92ea-3dd32951d740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " ‚úÖ PREDICTION SYSTEM COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üéØ YOUR DISPUTE RESOLUTION MODEL:\n",
      "\n",
      "üìä Model Performance:\n",
      "   ‚Ä¢ Model: Linear SVC\n",
      "   ‚Ä¢ Accuracy: 81.92%\n",
      "   ‚Ä¢ F1-Score: 0.7663\n",
      "   ‚Ä¢ Training samples: 125,250\n",
      "\n",
      "üé® Prediction Classes:\n",
      "   ‚Ä¢ favor_seller\n",
      "   ‚Ä¢ favour_customer\n",
      "   ‚Ä¢ split_payment\n",
      "\n",
      "üìù HOW TO USE THIS SYSTEM:\n",
      "\n",
      "1Ô∏è‚É£ SINGLE PREDICTION:\n",
      "   complaint = 'Your complaint text here'\n",
      "   result = predict_dispute_resolution(complaint)\n",
      "   print_prediction_result(result)\n",
      "\n",
      "2Ô∏è‚É£ BATCH PREDICTION:\n",
      "   complaints = ['complaint 1', 'complaint 2', 'complaint 3']\n",
      "   results_df = predict_batch_complaints(complaints)\n",
      "   print(results_df)\n",
      "\n",
      "3Ô∏è‚É£ SAVE PREDICTIONS:\n",
      "   save_predictions(results_df, 'my_predictions.csv')\n",
      "\n",
      "4Ô∏è‚É£ INTERACTIVE MODE:\n",
      "   interactive_predict()\n",
      "\n",
      "======================================================================\n",
      "üéâ CONGRATULATIONS! YOUR MODEL IS READY FOR PRODUCTION!\n",
      "======================================================================\n",
      "\n",
      "üí° NEXT STEPS:\n",
      "\n",
      "   ‚Ä¢ Test with real complaints from your dataset\n",
      "   ‚Ä¢ Deploy as a web API (Flask/FastAPI)\n",
      "   ‚Ä¢ Create a user interface\n",
      "   ‚Ä¢ Monitor model performance over time\n",
      "   ‚Ä¢ Retrain with new data periodically\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# CELL 13: Complete Summary and Usage Guide\n",
    "# ==================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" ‚úÖ PREDICTION SYSTEM COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüéØ YOUR DISPUTE RESOLUTION MODEL:\\n\")\n",
    "\n",
    "print(f\"üìä Model Performance:\")\n",
    "print(f\"   ‚Ä¢ Model: {metadata['model_name']}\")\n",
    "print(f\"   ‚Ä¢ Accuracy: {metadata['accuracy']:.2%}\")\n",
    "print(f\"   ‚Ä¢ F1-Score: {metadata['f1_score']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Training samples: {metadata['training_samples']:,}\")\n",
    "\n",
    "print(f\"\\nüé® Prediction Classes:\")\n",
    "for label in target_encoder.classes_:\n",
    "    print(f\"   ‚Ä¢ {label}\")\n",
    "\n",
    "print(f\"\\nüìù HOW TO USE THIS SYSTEM:\\n\")\n",
    "\n",
    "print(\"1Ô∏è‚É£ SINGLE PREDICTION:\")\n",
    "print(\"   complaint = 'Your complaint text here'\")\n",
    "print(\"   result = predict_dispute_resolution(complaint)\")\n",
    "print(\"   print_prediction_result(result)\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ BATCH PREDICTION:\")\n",
    "print(\"   complaints = ['complaint 1', 'complaint 2', 'complaint 3']\")\n",
    "print(\"   results_df = predict_batch_complaints(complaints)\")\n",
    "print(\"   print(results_df)\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ SAVE PREDICTIONS:\")\n",
    "print(\"   save_predictions(results_df, 'my_predictions.csv')\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ INTERACTIVE MODE:\")\n",
    "print(\"   interactive_predict()\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ CONGRATULATIONS! YOUR MODEL IS READY FOR PRODUCTION!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüí° NEXT STEPS:\\n\")\n",
    "print(\"   ‚Ä¢ Test with real complaints from your dataset\")\n",
    "print(\"   ‚Ä¢ Deploy as a web API (Flask/FastAPI)\")\n",
    "print(\"   ‚Ä¢ Create a user interface\")\n",
    "print(\"   ‚Ä¢ Monitor model performance over time\")\n",
    "print(\"   ‚Ä¢ Retrain with new data periodically\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c1919d7-39d3-44ec-a874-2b946760b13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING WITH REAL DATA FROM YOUR DATASET\n",
      "======================================================================\n",
      "\n",
      "üîÑ Loading sample from your cleaned dataset...\n",
      "‚úÖ Loaded 10 sample complaints\n",
      "\n",
      "üîÑ Making predictions on real data...\n",
      "\n",
      "üìä ACTUAL vs PREDICTED:\n",
      "======================================================================\n",
      "         actual    predicted match confidence\n",
      "favour_customer favor_seller     ‚ùå     56.01%\n",
      "   favor_seller favor_seller     ‚úÖ     74.33%\n",
      "   favor_seller favor_seller     ‚úÖ     77.70%\n",
      "   favor_seller favor_seller     ‚úÖ     55.40%\n",
      "   favor_seller favor_seller     ‚úÖ     62.79%\n",
      "favour_customer favor_seller     ‚ùå     70.19%\n",
      "   favor_seller favor_seller     ‚úÖ     75.11%\n",
      "   favor_seller favor_seller     ‚úÖ     68.45%\n",
      "   favor_seller favor_seller     ‚úÖ     76.83%\n",
      "   favor_seller favor_seller     ‚úÖ     71.08%\n",
      "\n",
      "üìà Sample Accuracy: 80.00%\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# CELL 14: Test with Real Data from Your Dataset\n",
    "# ==================================================\n",
    "\n",
    "print(\"üß™ TESTING WITH REAL DATA FROM YOUR DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load a small sample from your cleaned data\n",
    "try:\n",
    "    print(\"\\nüîÑ Loading sample from your cleaned dataset...\")\n",
    "    df_test = pd.read_csv('../data/processed/complaints_cleaned.csv', nrows=10)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(df_test)} sample complaints\")\n",
    "    \n",
    "    # Get actual labels and predictions\n",
    "    print(\"\\nüîÑ Making predictions on real data...\")\n",
    "    \n",
    "    comparison_results = []\n",
    "    \n",
    "    for idx, row in df_test.iterrows():\n",
    "        complaint_text = row['complaint_text_processed']\n",
    "        actual_label = row['dispute_resolution']\n",
    "        \n",
    "        # Make prediction\n",
    "        result = predict_dispute_resolution(complaint_text)\n",
    "        \n",
    "        if 'error' not in result:\n",
    "            predicted_label = result['prediction']\n",
    "            confidence = max(result['confidence_scores'].values())\n",
    "            \n",
    "            comparison_results.append({\n",
    "                'actual': actual_label,\n",
    "                'predicted': predicted_label,\n",
    "                'match': '‚úÖ' if actual_label == predicted_label else '‚ùå',\n",
    "                'confidence': f'{confidence:.2%}'\n",
    "            })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    \n",
    "    print(\"\\nüìä ACTUAL vs PREDICTED:\")\n",
    "    print(\"=\"*70)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = (comparison_df['match'] == '‚úÖ').sum() / len(comparison_df)\n",
    "    print(f\"\\nüìà Sample Accuracy: {accuracy:.2%}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"\\n‚ö†Ô∏è Could not find cleaned dataset file\")\n",
    "    print(\"   This is optional - you can skip this cell\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0ede9b-f689-435a-aaa0-a168cb91b293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2025.12-py312",
   "language": "python",
   "name": "conda-env-anaconda-2025.12-py312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
